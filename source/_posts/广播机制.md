---
title: 数据操作
mathjax: true
index_img: /img/zb.jpg
categories:
  - 深度学习
date: 2024-07-28 17:34:08
tags:
---
# 运算符
在 pythorch 中，我们的兴趣不仅仅只是读取数据和写入数据。我们想在这这些数据上执行数学运算，其中最简单和最有用的操作就是按元素（elementwise）运算。它们将标准标量运算符应用于数组中的每个元素。对于将两个数组作为输入的函数，暗元素运算将二元运算符应用于两个数组中的每对位置对应的元素。我们可以基于任何从标量到标量的函数来创建按元素函数。

在数学表示法中，我们将通过符号$f:\mathbb{R} \rightarrow \mathbb{R}$来表示一元标量运算符（只接收一个输入）。 这意味着该函数从任何实数（$\mathbb{R}$）映射到另一个实数。 同样，我们通过符号$f:\mathbb{R},\mathbb{R} \rightarrow \mathbb{R}$表示二元标量运算符，这意味着该函数接收两个输入，并产生一个输出。 给定同一形状的任意两个向量$u$和$v$和二元运算符$f$,我们可以得到向量$c=F(u,v)$。具体计算方法是$c_i \leftarrow f(u_i,v_i)$，其中$c_i、u_i$和$v_i$分别是向量$c、u$和$v$中的元素。 在这里，我们通过将标量函数升级为按元素向量运算来生成向量值 $F:\mathbb{R}^d,\mathbb{R}^d \rightarrow \mathbb{R}^d$。

对于任意具有相同形状的张量， 常见的标准算术运算符（+、-、*、/和**）都可以被升级为按元素运算。 我们可以在同一形状的任意两个张量上调用按元素操作。 在下面的例子中，我们使用逗号来表示一个具有5个元素的元组，其中每个元素都是按元素操作的结果。
```pytorch
x = torch.tensor([1.0, 2, 4, 8])
y = torch.tensor([2, 2, 2, 2])
x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算


------------结果--------------

(tensor([ 3.,  4.,  6., 10.]),
 tensor([-1.,  0.,  2.,  6.]),
 tensor([ 2.,  4.,  8., 16.]),
 tensor([0.5000, 1.0000, 2.0000, 4.0000]),
 tensor([ 1.,  4., 16., 64.]))
```
“按元素”方式可以应用更多的计算，包括像求幂这样的一元运算符。
```pytorch
torch.exp(x)

------------结果--------------


tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])
```

除了按元素计算外，我们还可以执行线性代数运算，包括向量点积和矩阵乘法。 

我们也可以把多个张量连结（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。 我们只需要提供张量列表，并给出沿哪个轴连结。 下面的例子分别演示了当我们沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵时，会发生什么情况。 我们可以看到，第一个输出张量的轴-0长度（6）是两个输入张量轴-0长度的总和（3+3）； 第二个输出张量的轴-1长度（8）是两个输入张量轴-1长度的总和（4+4）。
```pytorch
X = torch.arange(12, dtype=torch.float32).reshape((3,4))
Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)


------------结果--------------

(tensor([[ 0.,  1.,  2.,  3.],
         [ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.],
         [ 2.,  1.,  4.,  3.],
         [ 1.,  2.,  3.,  4.],
         [ 4.,  3.,  2.,  1.]]),
 tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))
```

# 广播机制
在上面的部分中，我们看到了如何在相同形状的两个张量上执行按元素操作。 在某些情况下，即使形状不同，我们仍然可以通过调用 广播机制（broadcasting mechanism）来执行按元素操作。 这种机制的工作方式如下：

1. 通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状；

2. 对生成的数组执行按元素操作。

在大多数情况下，我们将沿着数组中长度为1的轴进行广播，如下例子：
```pytorch
a = torch.arange(3).reshape((3, 1))
b = torch.arange(2).reshape((1, 2))
a, b
```
由于a和b分别是$3 \times 1$和 $1 \times 2$矩阵，如果让它们相加，它们的形状不匹配。 我们将两个矩阵广播为一个更大的$3\times2$矩阵，如下所示：矩阵a将复制列， 矩阵b将复制行，然后再按元素相加。
```pytorch
a + b


------------结果--------------


tensor([[0, 1],
        [1, 2],
        [2, 3]])
```